{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Text_Processed', 'REFERENCE_ID', 'YEAR', 'TITLE'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_pickle('lemmatized.pkl')\n",
    "df = pd.read_pickle('nltk_stemmed.pkl')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize data stored in text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df['Text_Processed_str'] = df['Text_Processed'].str.join(sep = ' ')\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', max_features=5000)\n",
    "x_counts = vectorizer.fit_transform(df['Text_Processed_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfidf encoding\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(x_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMF topic modeling\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "no_topics = 20\n",
    "model = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(X_train_tfidf.T)\n",
    "\n",
    "nmf = model.fit(X_train_tfidf.T)\n",
    "\n",
    "#nmf = LatentDirichletAllocation(n_components=no_topics, random_state=100).fit(X_train_tfidf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensionality reduction\n",
    "from sklearn.manifold import TSNE\n",
    "nmf_embedded = TSNE(n_components=3, perplexity=40).fit_transform(nmf.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all data back together\n",
    "reduced = pd.DataFrame(nmf_embedded)\n",
    "jdf = reduced.join(df)\n",
    "\n",
    "#Match categories to original titles\n",
    "topic_values = model.fit_transform(X_train_tfidf)\n",
    "topic_values.shape\n",
    "nmf.components_.shape\n",
    "jdf['category'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top words ###Fix meeeeeeee##\n",
    "def get_nmf_topics(model, n_top_words):\n",
    "    \n",
    "    #the word ids obtained need to be reverse-mapped to the words so we can print the topic names.\n",
    "    feat_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    word_dict = {};\n",
    "    for i in range(no_topics):\n",
    "        \n",
    "        #for each topic, obtain the largest values, and add the words they map to into the dictionary.\n",
    "        words_ids = model.components_[i].argsort()[:-n_top_words - 1:-1]\n",
    "        words = [feat_names[key] for key in words_ids]\n",
    "        wordstring = str(\"\")\n",
    "        for word in words:\n",
    "            wordstring += word + \" \"\n",
    "        word_dict[i] = wordstring\n",
    "    \n",
    "    return pd.Series(word_dict);\n",
    "\n",
    "top_words = pd.DataFrame(get_nmf_topics(nmf, 5), columns = ['top words'])\n",
    "export = pd.merge(top_words, jdf, right_on='category', left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export.to_pickle('clustered.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export.to_csv('clustered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(nmf.fit_transform(X_train_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TSNE in module sklearn.manifold._t_sne:\n",
      "\n",
      "class TSNE(sklearn.base.BaseEstimator)\n",
      " |  t-distributed Stochastic Neighbor Embedding.\n",
      " |  \n",
      " |  t-SNE [1] is a tool to visualize high-dimensional data. It converts\n",
      " |  similarities between data points to joint probabilities and tries\n",
      " |  to minimize the Kullback-Leibler divergence between the joint\n",
      " |  probabilities of the low-dimensional embedding and the\n",
      " |  high-dimensional data. t-SNE has a cost function that is not convex,\n",
      " |  i.e. with different initializations we can get different results.\n",
      " |  \n",
      " |  It is highly recommended to use another dimensionality reduction\n",
      " |  method (e.g. PCA for dense data or TruncatedSVD for sparse data)\n",
      " |  to reduce the number of dimensions to a reasonable amount (e.g. 50)\n",
      " |  if the number of features is very high. This will suppress some\n",
      " |  noise and speed up the computation of pairwise distances between\n",
      " |  samples. For more tips see Laurens van der Maaten's FAQ [2].\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <t_sne>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_components : int, optional (default: 2)\n",
      " |      Dimension of the embedded space.\n",
      " |  \n",
      " |  perplexity : float, optional (default: 30)\n",
      " |      The perplexity is related to the number of nearest neighbors that\n",
      " |      is used in other manifold learning algorithms. Larger datasets\n",
      " |      usually require a larger perplexity. Consider selecting a value\n",
      " |      between 5 and 50. Different values can result in significanlty\n",
      " |      different results.\n",
      " |  \n",
      " |  early_exaggeration : float, optional (default: 12.0)\n",
      " |      Controls how tight natural clusters in the original space are in\n",
      " |      the embedded space and how much space will be between them. For\n",
      " |      larger values, the space between natural clusters will be larger\n",
      " |      in the embedded space. Again, the choice of this parameter is not\n",
      " |      very critical. If the cost function increases during initial\n",
      " |      optimization, the early exaggeration factor or the learning rate\n",
      " |      might be too high.\n",
      " |  \n",
      " |  learning_rate : float, optional (default: 200.0)\n",
      " |      The learning rate for t-SNE is usually in the range [10.0, 1000.0]. If\n",
      " |      the learning rate is too high, the data may look like a 'ball' with any\n",
      " |      point approximately equidistant from its nearest neighbours. If the\n",
      " |      learning rate is too low, most points may look compressed in a dense\n",
      " |      cloud with few outliers. If the cost function gets stuck in a bad local\n",
      " |      minimum increasing the learning rate may help.\n",
      " |  \n",
      " |  n_iter : int, optional (default: 1000)\n",
      " |      Maximum number of iterations for the optimization. Should be at\n",
      " |      least 250.\n",
      " |  \n",
      " |  n_iter_without_progress : int, optional (default: 300)\n",
      " |      Maximum number of iterations without progress before we abort the\n",
      " |      optimization, used after 250 initial iterations with early\n",
      " |      exaggeration. Note that progress is only checked every 50 iterations so\n",
      " |      this value is rounded to the next multiple of 50.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         parameter *n_iter_without_progress* to control stopping criteria.\n",
      " |  \n",
      " |  min_grad_norm : float, optional (default: 1e-7)\n",
      " |      If the gradient norm is below this threshold, the optimization will\n",
      " |      be stopped.\n",
      " |  \n",
      " |  metric : string or callable, optional\n",
      " |      The metric to use when calculating distance between instances in a\n",
      " |      feature array. If metric is a string, it must be one of the options\n",
      " |      allowed by scipy.spatial.distance.pdist for its metric parameter, or\n",
      " |      a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.\n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix.\n",
      " |      Alternatively, if metric is a callable function, it is called on each\n",
      " |      pair of instances (rows) and the resulting value recorded. The callable\n",
      " |      should take two arrays from X as input and return a value indicating\n",
      " |      the distance between them. The default is \"euclidean\" which is\n",
      " |      interpreted as squared euclidean distance.\n",
      " |  \n",
      " |  init : string or numpy array, optional (default: \"random\")\n",
      " |      Initialization of embedding. Possible options are 'random', 'pca',\n",
      " |      and a numpy array of shape (n_samples, n_components).\n",
      " |      PCA initialization cannot be used with precomputed distances and is\n",
      " |      usually more globally stable than random initialization.\n",
      " |  \n",
      " |  verbose : int, optional (default: 0)\n",
      " |      Verbosity level.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default: None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.  Note that different initializations might result in\n",
      " |      different local minima of the cost function.\n",
      " |  \n",
      " |  method : string (default: 'barnes_hut')\n",
      " |      By default the gradient calculation algorithm uses Barnes-Hut\n",
      " |      approximation running in O(NlogN) time. method='exact'\n",
      " |      will run on the slower, but exact, algorithm in O(N^2) time. The\n",
      " |      exact algorithm should be used when nearest-neighbor errors need\n",
      " |      to be better than 3%. However, the exact method cannot scale to\n",
      " |      millions of examples.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Approximate optimization *method* via the Barnes-Hut.\n",
      " |  \n",
      " |  angle : float (default: 0.5)\n",
      " |      Only used if method='barnes_hut'\n",
      " |      This is the trade-off between speed and accuracy for Barnes-Hut T-SNE.\n",
      " |      'angle' is the angular size (referred to as theta in [3]) of a distant\n",
      " |      node as measured from a point. If this size is below 'angle' then it is\n",
      " |      used as a summary node of all points contained within it.\n",
      " |      This method is not very sensitive to changes in this parameter\n",
      " |      in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing\n",
      " |      computation time and angle greater 0.8 has quickly increasing error.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of parallel jobs to run for neighbors search. This parameter\n",
      " |      has no impact when ``metric=\"precomputed\"`` or\n",
      " |      (``metric=\"euclidean\"`` and ``method=\"exact\"``).\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  embedding_ : array-like, shape (n_samples, n_components)\n",
      " |      Stores the embedding vectors.\n",
      " |  \n",
      " |  kl_divergence_ : float\n",
      " |      Kullback-Leibler divergence after optimization.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Number of iterations run.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.manifold import TSNE\n",
      " |  >>> X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
      " |  >>> X_embedded = TSNE(n_components=2).fit_transform(X)\n",
      " |  >>> X_embedded.shape\n",
      " |  (4, 2)\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  [1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data\n",
      " |      Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.\n",
      " |  \n",
      " |  [2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding\n",
      " |      https://lvdmaaten.github.io/tsne/\n",
      " |  \n",
      " |  [3] L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms.\n",
      " |      Journal of Machine Learning Research 15(Oct):3221-3245, 2014.\n",
      " |      https://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TSNE\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_components=2, perplexity=30.0, early_exaggeration=12.0, learning_rate=200.0, n_iter=1000, n_iter_without_progress=300, min_grad_norm=1e-07, metric='euclidean', init='random', verbose=0, random_state=None, method='barnes_hut', angle=0.5, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Fit X into an embedded space.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array, shape (n_samples, n_features) or (n_samples, n_samples)\n",
      " |          If the metric is 'precomputed' X must be a square distance\n",
      " |          matrix. Otherwise it contains a sample per row. If the method\n",
      " |          is 'exact', X may be a sparse matrix of type 'csr', 'csc'\n",
      " |          or 'coo'. If the method is 'barnes_hut' and the metric is\n",
      " |          'precomputed', X may be a precomputed sparse graph.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |  \n",
      " |  fit_transform(self, X, y=None)\n",
      " |      Fit X into an embedded space and return that transformed\n",
      " |      output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array, shape (n_samples, n_features) or (n_samples, n_samples)\n",
      " |          If the metric is 'precomputed' X must be a square distance\n",
      " |          matrix. Otherwise it contains a sample per row. If the method\n",
      " |          is 'exact', X may be a sparse matrix of type 'csr', 'csc'\n",
      " |          or 'coo'. If the method is 'barnes_hut' and the metric is\n",
      " |          'precomputed', X may be a precomputed sparse graph.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape (n_samples, n_components)\n",
      " |          Embedding of the training data in low-dimensional space.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
